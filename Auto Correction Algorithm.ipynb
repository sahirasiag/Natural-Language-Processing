{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a file called **'shakespeare.txt'** as our corpus and to build our frequency dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below steps will be used to preprocess the text file:\n",
    "\n",
    "- Read the text file\n",
    "- Convert all the words to lowercase\n",
    "- Create a list of all the words in the text file\n",
    "- Create a vocabulary from the list\n",
    "\n",
    "We will perform the above tasks in the below function of **process_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        file_name: File (corpus) in current directory to read. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus in lower case. \n",
    "    \"\"\"\n",
    "    words = []\n",
    "\n",
    "    with open(file_name) as f:\n",
    "        text = f.read()                # read the text file\n",
    "        text_lowercase = text.lower()  # convert text to lowercase\n",
    "        words = re.findall(r'\\w+', text_lowercase)    # create a list of words\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary: 6116\n"
     ]
    }
   ],
   "source": [
    "# create vocabulary\n",
    "word_l = process_data('shakespeare.txt')\n",
    "vocab = set(word_l) \n",
    "\n",
    "print(f\"Length of vocabulary: \"+str(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Count Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build a word count dictionary where the key is a word and the value is the number of times the word appears in the list. We will implement the **get_count** function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(word_l):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''\n",
    "    \n",
    "    word_count_dict = {}\n",
    "    word_count_dict = Counter(word_l)\n",
    "    \n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of key value pairs in the word count dictionary: 6116\n",
      "The count for the word 'mine' is 116\n"
     ]
    }
   ],
   "source": [
    "# create the word count dictionary\n",
    "word_count_dict = get_count(word_l)\n",
    "print(f\"Number of key value pairs in the word count dictionary: \"+str(len(word_count_dict)))\n",
    "print(f\"The count for the word 'mine' is {word_count_dict.get('mine',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilities of words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compute the probability that each word will appear if randomly selected from the corpus of words using the below formula:\n",
    "$$P(w_i) = \\frac{C(w_i)}{M} \\$$\n",
    "where \n",
    "\n",
    "$C(w_i)$ is the total number of times $w_i$ appears in the corpus.\n",
    "\n",
    "$M$ is the total number of words in the corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}\n",
    "    \n",
    "    M = 0\n",
    "    for word in word_count_dict.keys():\n",
    "        M += word_count_dict[word]       # calculating total number of words in the corpus\n",
    "    \n",
    "    for word in word_count_dict.keys():\n",
    "        probs[word] = word_count_dict[word] / M    # calculting probability of each word\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of key value pairs in the probs dictionary: 6116\n",
      "P('mine') is 0.0022\n"
     ]
    }
   ],
   "source": [
    "probs = get_probs(word_count_dict)\n",
    "\n",
    "print(f\"Number of key value pairs in the probs dictionary: \" + str(len(probs)))\n",
    "print(f\"P('mine') is {probs['mine']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the functions to manipulate strings so that we can edit the erroneous strings and return the right spellings of the words. We will implement four functions: \n",
    "\n",
    "* `delete_letter`: given a word, it returns all the possible strings that have **one character removed**. \n",
    "* `switch_letter`: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
    "* `replace_letter`: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
    "* `insert_letter`: given a word, it returns all the possible strings that have an **additional character inserted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    \n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    # Create a list of 'splits'. This is all the ways a word can be split into Left and Right\n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    # Generating all words that result from deleting one character\n",
    "    delete_l = [L + R[1:] for L, R in split_l if R]\n",
    "\n",
    "    return delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: cans\n",
      "\n",
      "Delete word list:\n",
      "['ans', 'cns', 'cas', 'can']\n"
     ]
    }
   ],
   "source": [
    "word = \"cans\"\n",
    "delete_word_l = delete_letter(word)\n",
    "print(\"Original word: \" + word)\n",
    "print(\"\\nDelete word list:\")\n",
    "print(delete_word_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter(word):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent character switched\n",
    "    ''' \n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "\n",
    "    # All the ways a word can be split into Left and Right\n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    # Generating all words that result from switching adjacent letters\n",
    "    switch_l = [L + R[1] + R[0] + R[2:] for L, R in split_l if len(R) > 1]\n",
    "\n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: cans\n",
      "\n",
      "Switch word list:\n",
      "['acns', 'cnas', 'casn']\n"
     ]
    }
   ],
   "source": [
    "word = \"cans\"\n",
    "switch_word_l = switch_letter(word)\n",
    "print(\"Original word: \" + word)\n",
    "print(\"\\nSwitch word list:\")\n",
    "print(switch_word_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter(word):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    # All the ways a word can be split into Left and Right\n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    # Generating all words that result from replacing each letter with another letter from the alphabet\n",
    "    replace_l = [L + c + R[1:] for L, R in split_l if R for c in letters]\n",
    "    \n",
    "    # getting only unique words from the replace list\n",
    "    replace_set = set(replace_l)\n",
    "    \n",
    "    # removing the original word\n",
    "    replace_set.discard(word)\n",
    "    \n",
    "    # turn the set back into a list and sort it\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: cans\n",
      "\n",
      "Replace word list:\n",
      "['aans', 'bans', 'caas', 'cabs', 'cacs', 'cads', 'caes', 'cafs', 'cags', 'cahs', 'cais', 'cajs', 'caks', 'cals', 'cams', 'cana', 'canb', 'canc', 'cand', 'cane', 'canf', 'cang', 'canh', 'cani', 'canj', 'cank', 'canl', 'canm', 'cann', 'cano', 'canp', 'canq', 'canr', 'cant', 'canu', 'canv', 'canw', 'canx', 'cany', 'canz', 'caos', 'caps', 'caqs', 'cars', 'cass', 'cats', 'caus', 'cavs', 'caws', 'caxs', 'cays', 'cazs', 'cbns', 'ccns', 'cdns', 'cens', 'cfns', 'cgns', 'chns', 'cins', 'cjns', 'ckns', 'clns', 'cmns', 'cnns', 'cons', 'cpns', 'cqns', 'crns', 'csns', 'ctns', 'cuns', 'cvns', 'cwns', 'cxns', 'cyns', 'czns', 'dans', 'eans', 'fans', 'gans', 'hans', 'ians', 'jans', 'kans', 'lans', 'mans', 'nans', 'oans', 'pans', 'qans', 'rans', 'sans', 'tans', 'uans', 'vans', 'wans', 'xans', 'yans', 'zans']\n"
     ]
    }
   ],
   "source": [
    "word = \"cans\"\n",
    "replace_word_l = replace_letter(word)\n",
    "print(\"Original word: \" + word)\n",
    "print(\"\\nReplace word list:\")\n",
    "print(replace_word_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    # All the ways a word can be split into Left and Right\n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    \n",
    "    # Generating all words that result from inserting a letter\n",
    "    insert_l = [L + c + R[0:] for L, R in split_l for c in letters]\n",
    "\n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original word: cans\n",
      "\n",
      "Insert word list:\n",
      "['acans', 'bcans', 'ccans', 'dcans', 'ecans', 'fcans', 'gcans', 'hcans', 'icans', 'jcans', 'kcans', 'lcans', 'mcans', 'ncans', 'ocans', 'pcans', 'qcans', 'rcans', 'scans', 'tcans', 'ucans', 'vcans', 'wcans', 'xcans', 'ycans', 'zcans', 'caans', 'cbans', 'ccans', 'cdans', 'ceans', 'cfans', 'cgans', 'chans', 'cians', 'cjans', 'ckans', 'clans', 'cmans', 'cnans', 'coans', 'cpans', 'cqans', 'crans', 'csans', 'ctans', 'cuans', 'cvans', 'cwans', 'cxans', 'cyans', 'czans', 'caans', 'cabns', 'cacns', 'cadns', 'caens', 'cafns', 'cagns', 'cahns', 'cains', 'cajns', 'cakns', 'calns', 'camns', 'canns', 'caons', 'capns', 'caqns', 'carns', 'casns', 'catns', 'cauns', 'cavns', 'cawns', 'caxns', 'cayns', 'cazns', 'canas', 'canbs', 'cancs', 'cands', 'canes', 'canfs', 'cangs', 'canhs', 'canis', 'canjs', 'canks', 'canls', 'canms', 'canns', 'canos', 'canps', 'canqs', 'canrs', 'canss', 'cants', 'canus', 'canvs', 'canws', 'canxs', 'canys', 'canzs', 'cansa', 'cansb', 'cansc', 'cansd', 'canse', 'cansf', 'cansg', 'cansh', 'cansi', 'cansj', 'cansk', 'cansl', 'cansm', 'cansn', 'canso', 'cansp', 'cansq', 'cansr', 'canss', 'canst', 'cansu', 'cansv', 'cansw', 'cansx', 'cansy', 'cansz']\n"
     ]
    }
   ],
   "source": [
    "word = \"cans\"\n",
    "insert_word_l = insert_letter(word)\n",
    "print(\"Original word: \" + word)\n",
    "print(\"\\nInsert word list:\")\n",
    "print(insert_word_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the edits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit one letter\n",
    "\n",
    "The edit_one_letter function gives all the possible edits that are one edit away from a word. The edits consist of the replace, insert, delete, and optionally the switch operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    \n",
    "    # getting all the edited words\n",
    "    delete_l = delete_letter(word)\n",
    "    insert_l = insert_letter(word)\n",
    "    replace_l = replace_letter(word)\n",
    "    switch_l = switch_letter(word)\n",
    "    \n",
    "    # concatinating the lists\n",
    "    if allow_switches == True:\n",
    "        total_l = delete_l + insert_l + replace_l + switch_l\n",
    "    else:\n",
    "        total_l = delete_l + insert_l + replace_l\n",
    "\n",
    "    # converting into a set to remove duplicates\n",
    "    edit_one_set = set(total_l)\n",
    "\n",
    "    return edit_one_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word: my \n",
      "\n",
      "List of words one edit away: \n",
      "['amy', 'ay', 'bmy', 'by', 'cmy', 'cy', 'dmy', 'dy', 'emy', 'ey', 'fmy', 'fy', 'gmy', 'gy', 'hmy', 'hy', 'imy', 'iy', 'jmy', 'jy', 'kmy', 'ky', 'lmy', 'ly', 'm', 'ma', 'may', 'mb', 'mby', 'mc', 'mcy', 'md', 'mdy', 'me', 'mey', 'mf', 'mfy', 'mg', 'mgy', 'mh', 'mhy', 'mi', 'miy', 'mj', 'mjy', 'mk', 'mky', 'ml', 'mly', 'mm', 'mmy', 'mn', 'mny', 'mo', 'moy', 'mp', 'mpy', 'mq', 'mqy', 'mr', 'mry', 'ms', 'msy', 'mt', 'mty', 'mu', 'muy', 'mv', 'mvy', 'mw', 'mwy', 'mx', 'mxy', 'mya', 'myb', 'myc', 'myd', 'mye', 'myf', 'myg', 'myh', 'myi', 'myj', 'myk', 'myl', 'mym', 'myn', 'myo', 'myp', 'myq', 'myr', 'mys', 'myt', 'myu', 'myv', 'myw', 'myx', 'myy', 'myz', 'mz', 'mzy', 'nmy', 'ny', 'omy', 'oy', 'pmy', 'py', 'qmy', 'qy', 'rmy', 'ry', 'smy', 'sy', 'tmy', 'ty', 'umy', 'uy', 'vmy', 'vy', 'wmy', 'wy', 'xmy', 'xy', 'y', 'ym', 'ymy', 'yy', 'zmy', 'zy']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_word = \"my\"\n",
    "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
    "\n",
    "# turn into list to sort it, in order to view it\n",
    "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
    "\n",
    "print(f\"input word: {tmp_word} \\n\\nList of words one edit away: \\n{tmp_edit_one_l}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit two letters\n",
    "\n",
    "The edit_two_letters function gives all the possible edits that are two edits away from a word. To do so, we will get all the possible edits on a single word and then for each modified word, we will modify it again. The edits consist of the replace, insert, delete, and optionally the switch operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    # get all the words one edit away\n",
    "    edit_one_set = edit_one_letter(word, allow_switches)\n",
    "    edit_one_l = sorted(list(edit_one_set))\n",
    "    \n",
    "    # for each modified word, again get all the words one edit away\n",
    "    for edit_word in edit_one_l:\n",
    "        edit_two_word_set = edit_one_letter(edit_word, allow_switches)\n",
    "        edit_two_set = set.union(edit_two_set, edit_two_word_set)\n",
    "    \n",
    "    return edit_two_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word: my \n",
      "\n",
      "Length of list of words two edits away: 7154\n",
      "\n",
      "First 10 strings ['', 'a', 'aa', 'aamy', 'aay', 'ab', 'abmy', 'aby', 'ac', 'acmy']\n",
      "Last 10 strings ['zyt', 'zyu', 'zyv', 'zyw', 'zyx', 'zyy', 'zyz', 'zz', 'zzmy', 'zzy']\n"
     ]
    }
   ],
   "source": [
    "tmp_word = \"my\"\n",
    "tmp_edit_two_set = edit_two_letters(tmp_word)\n",
    "\n",
    "# turn into list to sort it, in order to view it\n",
    "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
    "\n",
    "print(f\"input word: {tmp_word} \\n\\nLength of list of words two edits away: {len(tmp_edit_two_l)}\\n\")\n",
    "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
    "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggest Spelling Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement `get_suggestions`, which returns a list of zero to n possible suggestion tuples of the form (word, probability_of_word). \n",
    "\n",
    "**Step 1:** Generate suggestions for a supplied word: \n",
    "* If the word is in the vocabulary, suggest the word. \n",
    "* Otherwise, if there are suggestions from `edit_one_letter` that are in the vocabulary, use those. \n",
    "* Otherwise, if there are suggestions from `edit_two_letters` that are in the vocabulary, use those. \n",
    "* Otherwise, suggest the input word.\n",
    "* The words generated from fewer edits are more likely than words with more edits.\n",
    "\n",
    "**Step 2**: Create a 'best_words' dictionary where the 'key' is a suggestion and the 'value' is the probability of that word in the vocabulary. If the word is not in the vocabulary, assign it a probability of 0.\n",
    "\n",
    "**Step 3**: Select the n best suggestions. There may be fewer than n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(word, probs, vocab, n=2):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections you want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    # get edited words\n",
    "    edit_one_set = edit_one_letter(word)\n",
    "    edit_two_set = edit_two_letters(word)\n",
    "    \n",
    "    # select the words that are in the dictionary\n",
    "    sug_word = []\n",
    "    if word in vocab:\n",
    "        sug_word.append(word)\n",
    "    \n",
    "    sug_edit_one_word = list(set.intersection(edit_one_set, vocab))\n",
    "    sug_edit_two_word = list(set.intersection(edit_two_set, vocab))\n",
    "    \n",
    "    # select the correct list of edited words (step 1 mentioned above)\n",
    "    suggestions = sug_word or sug_edit_one_word or sug_edit_two_word\n",
    "    \n",
    "    # get the probability of the words selected and store in a dictionary\n",
    "    best_words = {}\n",
    "    for word in suggestions:\n",
    "        best_words[word] = probs.get(word,0)\n",
    "    \n",
    "    # choose the n best words\n",
    "    best_words = Counter(best_words)\n",
    "    n_best = best_words.most_common(n)\n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(word):\n",
    "    print(\"Original Word: \" + word)\n",
    "    \n",
    "    corrections = get_suggestions(word, probs, vocab, 2)\n",
    "    \n",
    "    print(\"\\nSuggested Corrections:\")\n",
    "    for i, word_prob in enumerate(corrections):\n",
    "        print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: dys\n",
      "\n",
      "Suggested Corrections:\n",
      "word 0: days, probability 0.000410\n",
      "word 1: dye, probability 0.000019\n"
     ]
    }
   ],
   "source": [
    "test('dys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: cors\n",
      "\n",
      "Suggested Corrections:\n",
      "word 0: cars, probability 0.000019\n"
     ]
    }
   ],
   "source": [
    "test('cors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word: bmacc\n",
      "\n",
      "Suggested Corrections:\n",
      "word 0: black, probability 0.000354\n",
      "word 1: back, probability 0.000261\n"
     ]
    }
   ],
   "source": [
    "test('bmacc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
